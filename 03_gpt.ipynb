{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT2 large Language Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 1.54Git/s]                                                     \n",
      "Fetching encoder.json: 1.05Mit [00:00, 2.69Mit/s]                                                   \n",
      "Fetching hparams.json: 1.05Mit [00:00, 11.4Git/s]                                                   \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [02:29, 3.33Mit/s]                                  \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 1.61Git/s]                                               \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 4.87Mit/s]                                                \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 3.41Mit/s]                                                      \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(\n",
    "model_name= \"124M\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable model/wpe does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m session \u001b[39m=\u001b[39m gpt2\u001b[39m.\u001b[39mstart_tf_sess()\n\u001b[0;32m----> 2\u001b[0m gpt2\u001b[39m.\u001b[39;49mload_gpt2(session, model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m124M\u001b[39;49m\u001b[39m\"\u001b[39;49m, reuse\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/gpt_2.py:394\u001b[0m, in \u001b[0;36mload_gpt2\u001b[0;34m(sess, checkpoint, run_name, checkpoint_dir, model_name, model_dir, multi_gpu, reuse)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m multi_gpu:\n\u001b[1;32m    392\u001b[0m     gpus \u001b[39m=\u001b[39m get_available_gpus()\n\u001b[0;32m--> 394\u001b[0m output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mmodel(hparams\u001b[39m=\u001b[39;49mhparams, X\u001b[39m=\u001b[39;49mcontext, gpus\u001b[39m=\u001b[39;49mgpus, reuse\u001b[39m=\u001b[39;49mreuse)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m checkpoint\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatest\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    397\u001b[0m     ckpt \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39mlatest_checkpoint(checkpoint_path)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/gpt_2_simple/src/model.py:188\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(hparams, X, past, scope, gpus, reuse)\u001b[0m\n\u001b[1;32m    185\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m    186\u001b[0m batch, sequence \u001b[39m=\u001b[39m shape_list(X)\n\u001b[0;32m--> 188\u001b[0m wpe \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mget_variable(\u001b[39m'\u001b[39;49m\u001b[39mwpe\u001b[39;49m\u001b[39m'\u001b[39;49m, [hparams\u001b[39m.\u001b[39;49mn_ctx, hparams\u001b[39m.\u001b[39;49mn_embd],\n\u001b[1;32m    189\u001b[0m                      initializer\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mrandom_normal_initializer(stddev\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m))\n\u001b[1;32m    190\u001b[0m wte \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mget_variable(\u001b[39m'\u001b[39m\u001b[39mwte\u001b[39m\u001b[39m'\u001b[39m, [hparams\u001b[39m.\u001b[39mn_vocab, hparams\u001b[39m.\u001b[39mn_embd],\n\u001b[1;32m    191\u001b[0m                      initializer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mrandom_normal_initializer(stddev\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m))\n\u001b[1;32m    192\u001b[0m past_length \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m past \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m tf\u001b[39m.\u001b[39mshape(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mpast)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:1565\u001b[0m, in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mget_variable\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1550\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_variable\u001b[39m(name,\n\u001b[1;32m   1551\u001b[0m                  shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1563\u001b[0m                  synchronization\u001b[39m=\u001b[39mVariableSynchronization\u001b[39m.\u001b[39mAUTO,\n\u001b[1;32m   1564\u001b[0m                  aggregation\u001b[39m=\u001b[39mVariableAggregation\u001b[39m.\u001b[39mNONE):\n\u001b[0;32m-> 1565\u001b[0m   \u001b[39mreturn\u001b[39;00m get_variable_scope()\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   1566\u001b[0m       _get_default_variable_store(),\n\u001b[1;32m   1567\u001b[0m       name,\n\u001b[1;32m   1568\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1569\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1570\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1571\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1572\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1573\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1574\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1575\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1576\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   1577\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1578\u001b[0m       custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   1579\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1580\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1581\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:1275\u001b[0m, in \u001b[0;36mVariableScope.get_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1274\u001b[0m   dtype \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype\n\u001b[0;32m-> 1275\u001b[0m \u001b[39mreturn\u001b[39;00m var_store\u001b[39m.\u001b[39;49mget_variable(\n\u001b[1;32m   1276\u001b[0m     full_name,\n\u001b[1;32m   1277\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m   1278\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1279\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m   1280\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m   1281\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m   1282\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m   1283\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m   1284\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m   1285\u001b[0m     partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m   1286\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m   1287\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m   1288\u001b[0m     custom_getter\u001b[39m=\u001b[39;49mcustom_getter,\n\u001b[1;32m   1289\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m   1290\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m   1291\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:520\u001b[0m, in \u001b[0;36m_VariableStore.get_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    518\u001b[0m   \u001b[39mreturn\u001b[39;00m custom_getter(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcustom_getter_kwargs)\n\u001b[1;32m    519\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[39mreturn\u001b[39;00m _true_getter(\n\u001b[1;32m    521\u001b[0m       name,\n\u001b[1;32m    522\u001b[0m       shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    523\u001b[0m       dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    524\u001b[0m       initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    525\u001b[0m       regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    526\u001b[0m       reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    527\u001b[0m       trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    528\u001b[0m       collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    529\u001b[0m       caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    530\u001b[0m       partitioner\u001b[39m=\u001b[39;49mpartitioner,\n\u001b[1;32m    531\u001b[0m       validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    532\u001b[0m       use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    533\u001b[0m       constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    534\u001b[0m       synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    535\u001b[0m       aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:473\u001b[0m, in \u001b[0;36m_VariableStore.get_variable.<locals>._true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vars:\n\u001b[1;32m    468\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    469\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mNo partitioner was provided, but a partitioned version of the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    470\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mvariable was found: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m/part_0. Perhaps a variable of the same \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mname was already created with partitioning?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[0;32m--> 473\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_variable(\n\u001b[1;32m    474\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    475\u001b[0m     shape\u001b[39m=\u001b[39;49mshape,\n\u001b[1;32m    476\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    477\u001b[0m     initializer\u001b[39m=\u001b[39;49minitializer,\n\u001b[1;32m    478\u001b[0m     regularizer\u001b[39m=\u001b[39;49mregularizer,\n\u001b[1;32m    479\u001b[0m     reuse\u001b[39m=\u001b[39;49mreuse,\n\u001b[1;32m    480\u001b[0m     trainable\u001b[39m=\u001b[39;49mtrainable,\n\u001b[1;32m    481\u001b[0m     collections\u001b[39m=\u001b[39;49mcollections,\n\u001b[1;32m    482\u001b[0m     caching_device\u001b[39m=\u001b[39;49mcaching_device,\n\u001b[1;32m    483\u001b[0m     validate_shape\u001b[39m=\u001b[39;49mvalidate_shape,\n\u001b[1;32m    484\u001b[0m     use_resource\u001b[39m=\u001b[39;49muse_resource,\n\u001b[1;32m    485\u001b[0m     constraint\u001b[39m=\u001b[39;49mconstraint,\n\u001b[1;32m    486\u001b[0m     synchronization\u001b[39m=\u001b[39;49msynchronization,\n\u001b[1;32m    487\u001b[0m     aggregation\u001b[39m=\u001b[39;49maggregation)\n",
      "File \u001b[0;32m~/Library/Python/3.10/lib/python/site-packages/tensorflow/python/ops/variable_scope.py:857\u001b[0m, in \u001b[0;36m_VariableStore._get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39m# The code below handles only the case of creating a new variable.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[39mif\u001b[39;00m reuse \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mVariable \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m does not exist, or was not created with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mtf.get_variable(). Did you mean to set \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39mreuse=tf.AUTO_REUSE in VarScope?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n\u001b[1;32m    861\u001b[0m \u001b[39m# Create the tensor to initialize the variable with default value.\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m initializer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Variable model/wpe does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?"
     ]
    }
   ],
   "source": [
    "session = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(session, model_name=\"124M\", reuse= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt2\u001b[39m.\u001b[39mgenerate(session, prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe unicorn jumped over a bed on the slide\u001b[39m\u001b[39m\"\u001b[39m) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'session' is not defined"
     ]
    }
   ],
   "source": [
    "gpt2.generate(session, prefix=\"The unicorn jumped over a bed on the slide\")       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skakespeare Gpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "session2 = gpt2.start_tf_sess() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732547149.979854 2824900 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint models/124M/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 338025 tokens\n",
      "Training...\n",
      "[1 | 20.28] loss=4.11 avg=4.11\n",
      "[2 | 40.42] loss=3.70 avg=3.90\n",
      "[3 | 59.75] loss=3.97 avg=3.93\n",
      "[4 | 78.54] loss=3.68 avg=3.86\n",
      "[5 | 97.44] loss=3.70 avg=3.83\n",
      "[6 | 116.48] loss=3.65 avg=3.80\n",
      "[7 | 135.54] loss=3.63 avg=3.77\n",
      "[8 | 153.32] loss=4.05 avg=3.81\n",
      "[9 | 171.81] loss=3.93 avg=3.82\n",
      "[10 | 190.65] loss=3.48 avg=3.79\n",
      "[11 | 210.04] loss=3.50 avg=3.76\n",
      "[12 | 228.28] loss=3.50 avg=3.74\n",
      "[13 | 245.54] loss=3.70 avg=3.73\n",
      "[14 | 263.59] loss=3.68 avg=3.73\n",
      "[15 | 281.23] loss=3.53 avg=3.72\n",
      "[16 | 298.94] loss=3.69 avg=3.71\n",
      "[17 | 317.64] loss=3.36 avg=3.69\n",
      "[18 | 334.79] loss=3.56 avg=3.68\n",
      "[19 | 352.42] loss=3.56 avg=3.68\n",
      "[20 | 370.46] loss=3.68 avg=3.68\n",
      "[21 | 387.67] loss=3.09 avg=3.65\n",
      "[22 | 405.43] loss=3.58 avg=3.64\n",
      "[23 | 423.04] loss=3.27 avg=3.62\n",
      "[24 | 442.75] loss=3.48 avg=3.62\n",
      "[25 | 463.94] loss=3.53 avg=3.61\n",
      "[26 | 484.45] loss=3.41 avg=3.60\n",
      "[27 | 503.48] loss=3.47 avg=3.60\n",
      "[28 | 522.05] loss=3.57 avg=3.60\n",
      "[29 | 540.26] loss=3.54 avg=3.60\n",
      "[30 | 559.21] loss=3.43 avg=3.59\n",
      "[31 | 578.24] loss=3.62 avg=3.59\n",
      "[32 | 597.32] loss=3.27 avg=3.58\n",
      "[33 | 616.82] loss=3.25 avg=3.57\n",
      "[34 | 635.73] loss=3.17 avg=3.55\n",
      "[35 | 656.49] loss=3.33 avg=3.55\n",
      "[36 | 676.24] loss=3.45 avg=3.54\n",
      "[37 | 696.47] loss=3.51 avg=3.54\n",
      "[38 | 716.52] loss=3.40 avg=3.54\n",
      "[39 | 736.71] loss=3.35 avg=3.53\n",
      "[40 | 757.41] loss=3.20 avg=3.52\n",
      "[41 | 779.52] loss=3.38 avg=3.52\n",
      "[42 | 799.54] loss=3.43 avg=3.52\n",
      "[43 | 818.69] loss=3.37 avg=3.51\n",
      "[44 | 838.03] loss=3.36 avg=3.51\n",
      "[45 | 858.89] loss=3.49 avg=3.51\n",
      "[46 | 879.81] loss=3.25 avg=3.50\n",
      "[47 | 899.09] loss=3.48 avg=3.50\n",
      "[48 | 917.92] loss=3.61 avg=3.50\n",
      "[49 | 937.13] loss=3.37 avg=3.50\n",
      "[50 | 959.13] loss=3.70 avg=3.50\n",
      "[51 | 980.24] loss=3.33 avg=3.50\n",
      "[52 | 1000.99] loss=3.57 avg=3.50\n",
      "[53 | 1021.40] loss=3.08 avg=3.49\n",
      "[54 | 1041.17] loss=3.15 avg=3.48\n",
      "[55 | 1060.99] loss=3.19 avg=3.48\n",
      "[56 | 1083.86] loss=3.37 avg=3.47\n",
      "[57 | 1105.65] loss=3.17 avg=3.47\n",
      "[58 | 1127.08] loss=3.46 avg=3.47\n",
      "[59 | 1147.37] loss=3.39 avg=3.46\n",
      "[60 | 1167.39] loss=3.42 avg=3.46\n",
      "[61 | 1186.74] loss=3.41 avg=3.46\n",
      "[62 | 1205.19] loss=3.17 avg=3.46\n",
      "[63 | 1222.93] loss=3.11 avg=3.45\n",
      "[64 | 1241.93] loss=3.29 avg=3.45\n",
      "[65 | 1263.48] loss=3.07 avg=3.44\n",
      "[66 | 1284.21] loss=3.12 avg=3.43\n",
      "[67 | 1303.61] loss=3.03 avg=3.42\n",
      "[68 | 1322.32] loss=3.26 avg=3.42\n",
      "[69 | 1341.37] loss=3.26 avg=3.42\n",
      "[70 | 1359.68] loss=3.41 avg=3.42\n",
      "[71 | 1379.06] loss=3.16 avg=3.41\n",
      "[72 | 1398.38] loss=3.03 avg=3.40\n",
      "[73 | 1416.51] loss=3.31 avg=3.40\n",
      "[74 | 1436.06] loss=3.33 avg=3.40\n",
      "[75 | 1456.44] loss=3.39 avg=3.40\n",
      "[76 | 1476.72] loss=3.27 avg=3.40\n",
      "[77 | 1497.03] loss=3.19 avg=3.39\n",
      "[78 | 1516.67] loss=3.08 avg=3.39\n",
      "[79 | 1534.62] loss=3.18 avg=3.38\n",
      "[80 | 1553.24] loss=3.16 avg=3.38\n",
      "[81 | 1574.29] loss=3.06 avg=3.37\n",
      "[82 | 1595.75] loss=3.17 avg=3.37\n",
      "[83 | 1616.68] loss=3.22 avg=3.37\n",
      "[84 | 1636.12] loss=3.14 avg=3.36\n",
      "[85 | 1654.48] loss=3.29 avg=3.36\n",
      "[86 | 1674.48] loss=3.19 avg=3.36\n",
      "[87 | 1694.19] loss=3.14 avg=3.36\n",
      "[88 | 1717.81] loss=2.87 avg=3.35\n",
      "[89 | 1740.58] loss=3.47 avg=3.35\n",
      "[90 | 1761.50] loss=3.35 avg=3.35\n",
      "[91 | 1782.08] loss=3.18 avg=3.35\n",
      "[92 | 1802.33] loss=3.28 avg=3.35\n",
      "[93 | 1822.29] loss=3.15 avg=3.34\n",
      "[94 | 1842.37] loss=3.08 avg=3.34\n",
      "[95 | 1861.34] loss=3.29 avg=3.34\n",
      "[96 | 1881.17] loss=3.00 avg=3.33\n",
      "[97 | 1900.02] loss=3.23 avg=3.33\n",
      "[98 | 1918.03] loss=3.04 avg=3.33\n",
      "[99 | 1936.22] loss=3.11 avg=3.32\n",
      "[100 | 1953.85] loss=3.24 avg=3.32\n",
      "Saving checkpoint/shakespeare/model-100\n"
     ]
    }
   ],
   "source": [
    "gpt2.finetune(\n",
    "    session2,\n",
    "    \"shakespeare.txt\",\n",
    "    model_name= \"124M\",\n",
    "    steps= 100, \n",
    "    run_name= \"shakespeare\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rama says no.\n",
      "\n",
      "I say no\n",
      "\n",
      "I say no.\n",
      "\n",
      "BUCKINGHAM:\n",
      "\n",
      "What is the matter, sir?\n",
      "\n",
      "WARWICK:\n",
      "Away, go.\n",
      "\n",
      "BUCKINGHAM:\n",
      "No, sir, I say no,\n",
      "I say no, I say no.\n",
      "\n",
      "WARWICK:\n",
      "Why, that's like a question, madam,\n",
      "Why, I say no, I say no, I say no,\n",
      "Why, I say no, I say no, and all is well.\n",
      "\n",
      "BUCKINGHAM:\n",
      "What's the matter, sir?\n",
      "\n",
      "WARWICK:\n",
      "Aquatic!\n",
      "\n",
      "WARWICK:\n",
      "Aquatic!\n",
      "\n",
      "BUCKINGHAM:\n",
      "I'll say it is a question.\n",
      "\n",
      "WARWICK:\n",
      "I'll say it is a question.\n",
      "\n",
      "WARWICK:\n",
      "I'll say it is a question.\n",
      "\n",
      "BUCKINGHAM:\n",
      "A question, sir?\n",
      "\n",
      "WARWICK:\n",
      "A question.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Aquestion, sir.\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir.\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir.\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir.\n",
      "\n",
      "BUCKINGHAM:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir?\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir?\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir;\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir?\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "BUCKINGHAM:\n",
      "I'll say it is a question;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a question, sir;\n",
      "a prospect, sir.\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "BUCKINGHAM:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "BUCKINGHAM:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir!\n",
      "\n",
      "WARWICK:\n",
      "Aquestion, sir\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(\n",
    "    session2, \n",
    "    prefix=\"Rama says no\",\n",
    "    run_name= \"shakespeare\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
