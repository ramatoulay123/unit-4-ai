{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning with Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             file_path   label\n",
      "0       flower_photos/roses/16209331331_343c899d38.jpg   roses\n",
      "1        flower_photos/roses/5777669976_a205f61e5b.jpg   roses\n",
      "2      flower_photos/roses/4860145119_b1c3cbaa4e_n.jpg   roses\n",
      "3       flower_photos/roses/15011625580_7974c44bce.jpg   roses\n",
      "4     flower_photos/roses/17953368844_be3d18cf30_m.jpg   roses\n",
      "...                                                ...     ...\n",
      "3665     flower_photos/tulips/134143359_71fa8dd9a4.jpg  tulips\n",
      "3666    flower_photos/tulips/3637371174_a8dfcc1b35.jpg  tulips\n",
      "3667  flower_photos/tulips/6948239566_0ac0a124ee_n.jpg  tulips\n",
      "3668    flower_photos/tulips/2834890466_1cf220fba1.jpg  tulips\n",
      "3669   flower_photos/tulips/13953090784_0c7d7a904e.jpg  tulips\n",
      "\n",
      "[3670 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for dir, x, files in os.walk(\"flower_photos\"): \n",
    "      label = dir.split(\"/\")[-1]\n",
    "  \n",
    "\n",
    "      for file in files:\n",
    "        path = os.path.join(dir, file)\n",
    "\n",
    "\n",
    "        data.append([path,label])\n",
    "\n",
    "#print(data)\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"file_path\",\"label\"])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2936 validated image filenames belonging to 5 classes.\n",
      "Found 734 validated image filenames belonging to 5 classes.\n",
      "dict_items([('daisy', 0), ('dandelion', 1), ('roses', 2), ('sunflowers', 3), ('tulips', 4)])\n"
     ]
    }
   ],
   "source": [
    "train_gen = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    x_col = \"file_path\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (224, 224),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\", \n",
    "    shuffle = \"True\", \n",
    "    subset = \"training\"\n",
    ")\n",
    "\n",
    "valid_gen = datagen.flow_from_dataframe(\n",
    "    dataframe = df,\n",
    "    x_col = \"file_path\",\n",
    "    y_col = \"label\",\n",
    "    target_size = (224, 224),\n",
    "    color_mode = \"rgb\",\n",
    "    batch_size = 32,\n",
    "    class_mode = \"categorical\", \n",
    "    shuffle = \"True\", \n",
    "    subset = \"validation\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = EfficientNetB3(\n",
    "    include_top= False, \n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3), \n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(rate=.45, seed=123),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    Adamax(learning_rate= .0001), \n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'acc', \n",
    "        tf.keras.metrics.Precision(), \n",
    "        tf.keras.metrics.Recall(), \n",
    "        tf.keras.metrics.AUC()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    patience = 10,\n",
    "    min_delta = 0,\n",
    "    monitor = \"val_loss\",\n",
    "    verbose = 0, \n",
    "    restore_best_weights = True,\n",
    "    baseline = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Cohort23/Library/Python/3.10/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 3s/step - acc: 0.3368 - auc_1: 0.6431 - loss: 1.9667 - precision_1: 0.3825 - recall_1: 0.2599 - val_acc: 0.2193 - val_auc_1: 0.6155 - val_loss: 1.9384 - val_precision_1: 0.2127 - val_recall_1: 0.1322\n",
      "Epoch 2/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 3s/step - acc: 0.7342 - auc_1: 0.9262 - loss: 0.7689 - precision_1: 0.8052 - recall_1: 0.6599 - val_acc: 0.1240 - val_auc_1: 0.5135 - val_loss: 3.0619 - val_precision_1: 0.1294 - val_recall_1: 0.1049\n",
      "Epoch 3/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 3s/step - acc: 0.8241 - auc_1: 0.9684 - loss: 0.5005 - precision_1: 0.8817 - recall_1: 0.7737 - val_acc: 0.1240 - val_auc_1: 0.4710 - val_loss: 3.8293 - val_precision_1: 0.1303 - val_recall_1: 0.1172\n",
      "Epoch 4/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 3s/step - acc: 0.8833 - auc_1: 0.9840 - loss: 0.3478 - precision_1: 0.9147 - recall_1: 0.8565 - val_acc: 0.1240 - val_auc_1: 0.4441 - val_loss: 4.3726 - val_precision_1: 0.1278 - val_recall_1: 0.1172\n",
      "Epoch 5/5\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 3s/step - acc: 0.8973 - auc_1: 0.9889 - loss: 0.2888 - precision_1: 0.9237 - recall_1: 0.8742 - val_acc: 0.1226 - val_auc_1: 0.4265 - val_loss: 4.8065 - val_precision_1: 0.1298 - val_recall_1: 0.1199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29361ffa0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_gen,\n",
    "    validation_data = valid_gen,\n",
    "    epochs = 5,\n",
    "    validation_steps = None, \n",
    "    shuffle = False,\n",
    "    callbacks = early_stopping, \n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"flowers.keras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('daisy', 0), ('dandelion', 1), ('roses', 2), ('sunflowers', 3), ('tulips', 4)])\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x337d37910> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "your flower is a: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.saving import load_model \n",
    "import numpy as np \n",
    "\n",
    "\n",
    "model = load_model(\"flowers.keras\") \n",
    "\n",
    "input_image = cv2.imread(\"flower_photos/daisy/5673551_01d1ea993e_n.jpg\") \n",
    "\n",
    "input_image_resize = cv2.resize(input_image,  (224,224,))\n",
    "\n",
    "input_image_scaled = input_image_resize/225\n",
    "\n",
    "image_reshaped = np.reshape(input_image_scaled, [1, 224, 224, 3]) \n",
    "\n",
    "\n",
    "\n",
    "print(train_gen.class_indices.items())\n",
    "\n",
    "input_prediction = model.predict(image_reshaped) \n",
    "\n",
    "print(\"your flower is a:\", + np.argmax(input_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
